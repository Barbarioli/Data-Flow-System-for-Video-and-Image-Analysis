{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "k6xg58fu8Udp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Barbarioli/Pipeline/blob/master/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TasSVUUR73wj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "IA8Pp2gN78Bw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Packages"
      ]
    },
    {
      "metadata": {
        "id": "9lNVL4aii_l5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multiprocessing"
      ]
    },
    {
      "metadata": {
        "id": "4KiBe_rk7yUG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from multiprocessing import Process, JoinableQueue, Pool, Manager, cpu_count\n",
        "from time import sleep\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import sys\n",
        "import pathlib\n",
        "import logging\n",
        "import traceback \n",
        "import socket\n",
        "import time\n",
        "import shutil\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import \\\n",
        "    ReduceLROnPlateau as ReduceLROnPlateauPyTorch\n",
        "from torch.optim.lr_scheduler import MultiStepLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ljwpzf18IYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "4d8cf43b-597b-40b4-eedf-9f143a793944"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41vxb3oj8KOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Photos\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYAw9XJwvhmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Loading modules"
      ]
    },
    {
      "metadata": {
        "id": "ly1s_98OvNFR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Changing path to folder\n",
        "sys.path.append(\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/utils\")\n",
        "\n",
        "from general_utils import OptimizerType\n",
        "from general_utils import SchedulerType\n",
        "from general_utils import LossType\n",
        "from general_utils import LossReduction\n",
        "from general_utils import TensorType\n",
        "from general_utils import PrecisionType\n",
        "from general_utils import additional_log_file\n",
        "from general_utils import mem_log_file\n",
        "from general_utils import get_log_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21QfgTTUwBoW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Changing path to folder\n",
        "sys.path.append(\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/pytorch_layers\")\n",
        "\n",
        "from AdamFloat16 import AdamFloat16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zk4_Qu9CwB0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "682514ea-3eb5-492d-dbd8-4c7449097ac3"
      },
      "cell_type": "code",
      "source": [
        "#Changing path to folder\n",
        "#sys.path.append(\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/datasets\")\n",
        "#from mnist import get_mnist\n",
        "#from cifar import get_cifar\n",
        "sys.path.append(\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/datasets/ucr\")\n",
        "from ucr import get_ucr"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4f15fe35395d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/datasets/ucr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mucr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ucr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_ucr'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-YV45u7ijH2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "55dd7a34-e185-4410-c6d0-d0b7d1461333"
      },
      "cell_type": "code",
      "source": [
        "# from cnns.nnlib.pytorch_architecture.model_utils import getModelPyTorch\n",
        "\n",
        "from cnns.nnlib.datasets.mnist import get_mnist\n",
        "from cnns.nnlib.datasets.cifar import get_cifar\n",
        "from cnns.nnlib.datasets.ucr.ucr import get_ucr\n",
        "from cnns.nnlib.utils.exec_args import get_args\n",
        "from cnns.nnlib.pytorch_experiments.utils.progress_bar import progress_bar\n",
        "from cnns.nnlib.pytorch_architecture.le_net import LeNet\n",
        "from cnns.nnlib.pytorch_architecture.resnet2d import resnet18\n",
        "from cnns.nnlib.pytorch_architecture.densenet import densenet_cifar\n",
        "from cnns.nnlib.pytorch_architecture.fcnn import FCNNPytorch\n",
        "from cnns.nnlib.utils.general_utils import NetworkType\n",
        "\n",
        "\"\"\"\n",
        "sources:\n",
        "https://devblogs.nvidia.com/apex-pytorch-easy-mixed-precision-training/\n",
        "\"\"\"\n",
        "try:\n",
        "    import apex\n",
        "except ImportError:\n",
        "    raise ImportError(\"\"\"Please install apex from \n",
        "    https://www.github.com/nvidia/apex to run this code.\"\"\")\n",
        "\n",
        "amp_handle = None\n",
        "# from apex.parallel import DistributedDataParallel as DDP\n",
        "# from apex.fp16_utils import input_to_half\n",
        "from apex.fp16_utils import network_to_half\n",
        "from apex.fp16_utils import FP16_Optimizer\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-177fd7011ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/bandlimited-cnns-master/cnns/nnlib/pytorch_experiments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamFloat16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamFloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# from cnns.nnlib.pytorch_architecture.model_utils import getModelPyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcnns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneral_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizerType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cnns'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "k6xg58fu8Udp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Loading"
      ]
    },
    {
      "metadata": {
        "id": "8xRzf1SV8Vkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load(path):\n",
        "  \"\"\"\n",
        "  path: path to the photos to be loaded\n",
        "  \"\"\"\n",
        "  image_files = sorted([os.path.join(path, file) for file in os.listdir(path) if file.endswith('.jpg')])\n",
        "  return image_files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2xYomWBiHjj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ]
    },
    {
      "metadata": {
        "id": "GRjwlRS5vGgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jJ4dG_8iGzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "b7d9482e-7a8e-42d8-f2df-771c1cd1382d"
      },
      "cell_type": "code",
      "source": [
        "models_folder_name = \"models\"\n",
        "models_dir = os.path.join(os.getcwd(), models_folder_name)\n",
        "print(\"models_dir: \", models_dir)\n",
        "pathlib.Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
        "# if not os.path.exists(models_dir):\n",
        "#     os.makedirs(models_dir)\n",
        "\n",
        "# plt.switch_backend('agg')\n",
        "\n",
        "args = get_args()\n",
        "\n",
        "current_file_name = __file__.split(\"/\")[-1].split(\".\")[0]\n",
        "print(\"current file name: \", current_file_name)\n",
        "\n",
        "if torch.cuda.is_available() and args.use_cuda:\n",
        "    print(\"cuda is available: \")\n",
        "    device = torch.device(\"cuda\")\n",
        "    # torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def getModelPyTorch(args):\n",
        "    \"\"\"\n",
        "    Get the PyTorch version of the FCNN model.\n",
        "    :param input_size: the length (width) of the time series.\n",
        "    :param num_classes: number of output classes.\n",
        "    :param in_channels: number of channels in the input data for a convolution.\n",
        "    :param out_channels: number of channels in the output of a convolution.\n",
        "    :param dtype: global - the type of torch data/weights.\n",
        "    :param flat_size: the size of the flat vector after the conv layers.\n",
        "    :return: the model.\n",
        "    \"\"\"\n",
        "    network_type = args.network_type\n",
        "    if network_type is NetworkType.LE_NET:\n",
        "        return LeNet(args=args)\n",
        "    elif network_type is NetworkType.FCNN_SMALL or (\n",
        "            network_type is NetworkType.FCNN_STANDARD):\n",
        "        if network_type is NetworkType.FCNN_SMALL:\n",
        "            args.out_channels = [1, 1, 1]\n",
        "        elif network_type is NetworkType.FCNN_STANDARD:\n",
        "            args.out_channels = [128, 256, 128]\n",
        "        return FCNNPytorch(args=args)\n",
        "    elif network_type == NetworkType.ResNet18:\n",
        "        return resnet18(args=args)\n",
        "    elif network_type == NetworkType.DenseNetCifar:\n",
        "        return densenet_cifar(args=args)\n",
        "    else:\n",
        "        raise Exception(\"Unknown network_type: \", network_type)\n",
        "\n",
        "\n",
        "def readucr(filename, data_type):\n",
        "    parent_path = os.path.split(os.path.abspath(dir_path))[0]\n",
        "    print(\"parent path: \", parent_path)\n",
        "    filepath = os.path.join(parent_path, ucr_data_folder, filename,\n",
        "                            filename + \"_\" + data_type)\n",
        "    print(\"filepath: \", filepath)\n",
        "    data = np.loadtxt(filepath, delimiter=',')\n",
        "    Y = data[:, 0]\n",
        "    X = data[:, 1:]\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def getData(fname):\n",
        "    x_train, y_train = readucr(fname + '/' + fname + '_TRAIN')\n",
        "    x_test, y_test = readucr(fname + '/' + fname + '_TEST')\n",
        "    num_classes = len(np.unique(y_test))\n",
        "    batch_size = min(x_train.shape[0] // 10, args.min_batch_size)\n",
        "\n",
        "    y_train = ((y_train - y_train.min()) / (y_train.max() - y_train.min()) * (\n",
        "            num_classes - 1)).astype(int)\n",
        "    y_test = ((y_test - y_test.min()) / (y_test.max() - y_test.min()) * (\n",
        "            num_classes - 1)).astype(int)\n",
        "\n",
        "    x_train_mean = x_train.mean()\n",
        "    x_train_std = x_train.std()\n",
        "    x_train = (x_train - x_train_mean) / x_train_std\n",
        "\n",
        "    x_test = (x_test - x_train_mean) / x_train_std\n",
        "    # Add a single channels at the end of the data.\n",
        "    x_train = x_train.reshape(x_train.shape + (1,))\n",
        "    x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, batch_size, num_classes\n",
        "\n",
        "\n",
        "# @profile\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, loss_function, args, epoch=None):\n",
        "    \"\"\"\n",
        "    Test the model and return test loss and accuracy.\n",
        "\n",
        "    :param model: deep learning model.\n",
        "    :param device: cpu or gpu.\n",
        "    :param test_loader: the input data.\n",
        "    :param dataset_type: test or train.\n",
        "    :param dtype: the data type of the tensor.\n",
        "    :param epoch: current epoch of the model training/testing.\n",
        "    :return: test loss and accuracy.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    #Profile inference time and memory\n",
        "    inference_time = 0\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    memory_tensor = 0\n",
        "    memory_cache = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        torch.cuda.empty_cache()\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device=device, dtype=args.dtype), target.to(\n",
        "                device)\n",
        "            start.record()\n",
        "            output = model(data)\n",
        "            end.record()\n",
        "            memory_tensor += torch.cuda.memory_allocated(device=None)\n",
        "            memory_cache += torch.cuda.memory_cached(device=None)\n",
        "            \n",
        "            torch.cuda.synchronize()\n",
        "            inference_time += start.elapsed_time(end)\n",
        "            test_loss += loss_function(output,\n",
        "                                       target).item()  # sum up batch loss\n",
        "            # get the index of the max log-probability\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            if args.log_conv_size is True:\n",
        "                with open(additional_log_file, \"a\") as file:\n",
        "                    file.write(\"\\n\")\n",
        "\n",
        "            if args.is_progress_bar:\n",
        "                progress_bar(total, len(test_loader.dataset), epoch=epoch,\n",
        "                             msg=\"Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)\" %\n",
        "                                 (test_loss / total, 100. * correct / total,\n",
        "                                  correct,\n",
        "                                  total))\n",
        "\n",
        "        # Test loss for the whole dataset.\n",
        "        inference_time = inference_time / total\n",
        "        test_loss /= total\n",
        "        accuracy = 100. * correct / total\n",
        "        memory_cache = int(memory_cache / len(test_loader))\n",
        "        memory_tensor = int(memory_tensor / len(test_loader))\n",
        "         \n",
        "        with open(\"memory_time_profile\", \"a\") as file:        \n",
        "            file.write(\"-compress-rate- \" + str(args.compress_rate) + \"accuracy \" + str(accuracy) + \" inference_time_milliseconds \" \\\n",
        "                + str(inference_time) + \" memory_tensor_mb: {}\".format(memory_tensor >> 20) + \\\n",
        "                \" memory_cache: {}\".format(memory_cache >> 20) + \"\\n\")\n",
        "        \n",
        "\n",
        "        return test_loss, accuracy\n",
        "\n",
        "# @profile\n",
        "def main(args):\n",
        "    \"\"\"\n",
        "    The main training.\n",
        "\n",
        "    :param dataset_name: the name of the dataset from UCR.\n",
        "    \"\"\"\n",
        "    is_debug = args.is_debug\n",
        "    dataset_name = args.dataset_name\n",
        "    preserve_energy = args.preserve_energy\n",
        "    compress_rate = args.compress_rate\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "    optimizer_type = args.optimizer_type\n",
        "    scheduler_type = args.scheduler_type\n",
        "    loss_type = args.loss_type\n",
        "    loss_reduction = args.loss_reduction\n",
        "\n",
        "    use_cuda = args.use_cuda\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    tensor_type = args.tensor_type\n",
        "    if use_cuda and args.noise_sigma is False:\n",
        "        if tensor_type is TensorType.FLOAT32:\n",
        "            cuda_type = torch.cuda.FloatTensor\n",
        "        elif tensor_type is TensorType.FLOAT16:\n",
        "            cuda_type = torch.cuda.HalfTensor\n",
        "        elif tensor_type is TensorType.DOUBLE:\n",
        "            cuda_type = torch.cuda.DoubleTensor\n",
        "        else:\n",
        "            raise Exception(f\"Unknown tensor type: {tensor_type}\")\n",
        "        # The below has to be disabled for normal distribution to work (add noise).\n",
        "        torch.set_default_tensor_type(cuda_type)\n",
        "    elif use_cuda is False and args.noise_sigma is False:\n",
        "        if tensor_type is TensorType.FLOAT32:\n",
        "            cpu_type = torch.FloatTensor\n",
        "        elif tensor_type is TensorType.FLOAT16:\n",
        "            cpu_type = torch.HalfTensor\n",
        "        elif tensor_type is TensorType.DOUBLE:\n",
        "            cpu_type = torch.DoubleTensor\n",
        "        else:\n",
        "            raise Exception(f\"Unknown tensor type: {tensor_type}\")\n",
        "        torch.set_default_tensor_type(cpu_type)\n",
        "\n",
        "    train_loader, dev_loader, test_loader = None, None, None\n",
        "\n",
        "    model = getModelPyTorch(args=args)\n",
        "    model.to(device)\n",
        "    # model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # https://pytorch.org/docs/master/notes/serialization.html\n",
        "    if args.model_path != \"no_model\":\n",
        "        model.load_state_dict(\n",
        "            torch.load(os.path.join(models_dir, args.model_path),\n",
        "                       map_location=device))\n",
        "        msg = \"loaded model: \" + args.model_path\n",
        "        # logger.info(msg)\n",
        "        print(msg)\n",
        "    if args.precision_type is PrecisionType.FP16:\n",
        "        # model.half()  # convert to half precision\n",
        "        model = network_to_half(model)\n",
        "    \"\"\"\n",
        "    You want to make sure that the BatchNormalization layers use float32 for \n",
        "    accumulation or you will have convergence issues.\n",
        "    https://discuss.pytorch.org/t/training-with-half-precision/11815\n",
        "    \"\"\"\n",
        "    # for layer in model.modules():\n",
        "    #     if isinstance(layer, nn.BatchNorm1d) or isinstance(layer,\n",
        "    #                                                        nn.BatchNorm2d):\n",
        "    #         layer.float()\n",
        "\n",
        "    params = model.parameters()\n",
        "    eps = 1e-8\n",
        "\n",
        "    if optimizer_type is OptimizerType.MOMENTUM:\n",
        "        optimizer = optim.SGD(params, lr=args.learning_rate,\n",
        "                              momentum=args.momentum,\n",
        "                              weight_decay=args.weight_decay)\n",
        "    elif optimizer_type is OptimizerType.ADAM_FLOAT16:\n",
        "        optimizer = AdamFloat16(params, lr=args.learning_rate, eps=eps)\n",
        "    elif optimizer_type is OptimizerType.ADAM:\n",
        "        optimizer = optim.Adam(params, lr=args.learning_rate,\n",
        "                               betas=(args.adam_beta1, args.adam_beta2),\n",
        "                               weight_decay=args.weight_decay, eps=eps)\n",
        "    else:\n",
        "        raise Exception(f\"Unknown optimizer type: {optimizer_type.name}\")\n",
        "\n",
        "    # https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "    if scheduler_type is SchedulerType.ReduceLROnPlateau:\n",
        "        scheduler = ReduceLROnPlateauPyTorch(optimizer=optimizer, mode='min',\n",
        "                                             factor=0.1, patience=10)\n",
        "    elif scheduler_type is SchedulerType.MultiStepLR:\n",
        "        scheduler = MultiStepLR(optimizer=optimizer, milestones=[150, 250])\n",
        "    else:\n",
        "        raise Exception(f\"Unknown scheduler type: {scheduler_type}\")\n",
        "\n",
        "    if args.precision_type is PrecisionType.FP16:\n",
        "        \"\"\"\n",
        "        amp_handle: tells it where back-propagation occurs so that it can \n",
        "        properly scale the loss and clear internal per-iteration state.\n",
        "        \"\"\"\n",
        "        # amp_handle = amp.init()\n",
        "        # optimizer = amp_handle.wrap_optimizer(optimizer)\n",
        "\n",
        "        # The optimizer supported by apex.\n",
        "        optimizer = FP16_Optimizer(optimizer,\n",
        "                                   static_loss_scale=args.static_loss_scale,\n",
        "                                   dynamic_loss_scale=args.dynamic_loss_scale,\n",
        "                                   verbose=True)\n",
        "\n",
        "    # Optionally resume from a checkpoint.\n",
        "    if args.resume:\n",
        "        # Use a local scope to avoid dangling references.\n",
        "        def resume():\n",
        "            if os.path.isfile(args.resume):\n",
        "                print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "                checkpoint = torch.load(args.resume,\n",
        "                                        map_location=lambda storage,\n",
        "                                                            loc: storage.cuda(\n",
        "                                            args.gpu))\n",
        "                args.start_epoch = checkpoint['epoch']\n",
        "                max_train_accuracy = checkpoint['max_train_accuracy']\n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "                # An FP16_Optimizer instance's state dict internally stashes the master params.\n",
        "                optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "                print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                      .format(args.resume, checkpoint['epoch']))\n",
        "                return max_train_accuracy\n",
        "            else:\n",
        "                print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "                return 0.0\n",
        "\n",
        "        max_train_accuracy = resume()\n",
        "\n",
        "    if loss_reduction is LossReduction.ELEMENTWISE_MEAN:\n",
        "        reduction_function = \"mean\"\n",
        "    elif loss_reduction is LossReduction.SUM:\n",
        "        reduction_function = \"sum\"\n",
        "    else:\n",
        "        raise Exception(f\"Unknown loss reduction: {loss_reduction}\")\n",
        "\n",
        "    if loss_type is LossType.CROSS_ENTROPY:\n",
        "        loss_function = torch.nn.CrossEntropyLoss(reduction=reduction_function)\n",
        "    elif loss_type is LossType.NLL:\n",
        "        loss_function = torch.nn.NLLLoss(reduction=reduction_function)\n",
        "    else:\n",
        "        raise Exception(f\"Unknown loss type: {loss_type}\")\n",
        "\n",
        "    test_time = time.time()\n",
        "    test(model = model, device = device, test_loader = test_loader, loss_function = loss_function, args = args)\n",
        "    print(\"test time\", time.time() - test_time)\n",
        "  \n",
        "    start_time = time.time()\n",
        "    hostname = socket.gethostname()\n",
        "    cuda_visible_devices = os.environ['CUDA_VISIBLE_DEVICES']\n",
        "    global_log_file = os.path.join(results_folder_name,\n",
        "                                   get_log_time() + \"-ucr-fcnn.log\")\n",
        "    args_str = args.get_str()\n",
        "    HEADER = \"hostname,\" + str(\n",
        "        hostname) + \",timestamp,\" + get_log_time() + \",\" + str(\n",
        "        args_str) + \",cuda_visible_devices,\" + str(cuda_visible_devices)\n",
        "\n",
        "    if args.precision_type is PrecisionType.AMP:\n",
        "        from apex import amp\n",
        "\n",
        "        amp_handle = amp.init(enabled=True)\n",
        "\n",
        "    if args.dataset == \"all\" or args.dataset == \"ucr\":\n",
        "        flist = os.listdir(ucr_path)\n",
        "    elif args.dataset == \"cifar10\":\n",
        "        flist = [\"cifar10\"]\n",
        "    elif args.dataset == \"cifar100\":\n",
        "        flist = [\"cifar100\"]\n",
        "    elif args.dataset == \"mnist\":\n",
        "        flist = [\"mnist\"]\n",
        "\n",
        "    else:\n",
        "        raise AttributeError(\"Unknown dataset: \", args.dataset)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA is available\")\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"CUDA is not available\")\n",
        "\n",
        "    # flist = sorted(flist, key=lambda s: s.lower())\n",
        "    # flist = flist[3:]  # start from Beef\n",
        "    # reversed(flist)\n",
        "    print(\"flist: \", flist)\n",
        "    for dataset_name in flist:\n",
        "        args.dataset_name = dataset_name\n",
        "        print(\"Dataset: \", dataset_name)\n",
        "        for preserve_energy in args.preserve_energies:\n",
        "            print(\"preserve energy: \", preserve_energy)\n",
        "            args.preserve_energy = preserve_energy\n",
        "            for compress_rate in args.compress_rates:\n",
        "                print(\"compress rate: \", compress_rate)\n",
        "                args.compress_rate = compress_rate\n",
        "                for noise_sigma in args.noise_sigmas:\n",
        "                    print(\"noise sigma: \", noise_sigma)\n",
        "                    args.noise_sigma = noise_sigma\n",
        "                    start_training = time.time()\n",
        "                    try:\n",
        "                        main(args=args)\n",
        "                    except RuntimeError as err:\n",
        "                        print(f\"ERROR: {dataset_name}. \"\n",
        "                              \"Details: \" + str(err))\n",
        "                        traceback.print_tb(err.__traceback__)\n",
        "                    print(\"elapsed time (sec): \", time.time() - start_training)\n",
        "\n",
        "    print(\"total elapsed time (sec): \", time.time() - start_time)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models_dir:  /content/models\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-83f1879518b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# plt.switch_backend('agg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcurrent_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_args' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Rvq2xaSA8WyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Operators"
      ]
    },
    {
      "metadata": {
        "id": "tb_TKmFe8Ypc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class image_loader(object):\n",
        "  \"\"\"Load images from a list of paths to a queue in order to be processed.\n",
        "  \n",
        "  Args:\n",
        "    data: list of paths to all images.\n",
        "    queue: queue to where the loaded images will be added.\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, data, queue):\n",
        "    self.queue = queue\n",
        "    self.data = iter(data)\n",
        "    \n",
        "  def __iter__(self):  \n",
        "    return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    if len(data) > 0:\n",
        "      self.queue.put(imread(data[-1]))\n",
        "      data.pop()\n",
        "      return\n",
        "    \n",
        "    else:\n",
        "      raise StopIteration\n",
        "      \n",
        "      \n",
        "class preprocessing(object):\n",
        "  \"\"\"Preprocess images resizing, cropping and converting to tensor\n",
        "  \n",
        "  Args:\n",
        "    input_queue: input queue with the images to be preprocessed.\n",
        "    output_queue: queue with the output images.\n",
        "    output_size (tuple): desired image size in a tuple of (height, width).\n",
        "    crop (boolean): randomly crop the image. If cropped it will not be resized.\n",
        "    totensor (boolean): if the images should be converted to tensor.\n",
        "    \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_queue, output_queue, output_size, crop = False, totensor = False):\n",
        "    self.input_queue = input_queue\n",
        "    self.output_queue = output_queue\n",
        "    self.size = output_size\n",
        "    self.crop = crop\n",
        "    self.tensor = totensor\n",
        "    \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "      \n",
        "  def __next__(self):\n",
        "    if self.input_queue.qsize() != 0:\n",
        "      \n",
        "      image = self.input_queue.get()\n",
        "      \n",
        "      if self.crop:\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.size\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "        image = image[top: top + new_h,\n",
        "                     left: left + new_w]\n",
        "        \n",
        "      else:\n",
        "        image = resize(image, self.size, anti_aliasing = True)\n",
        "      \n",
        "      if self.tensor:\n",
        "        image = image.transpose((2,0,1))\n",
        "        image = torch.from_numpy(image)\n",
        "        \n",
        "      self.output_queue.put(image)\n",
        "      \n",
        "      \n",
        "      \n",
        "class inference(object):\n",
        "  \"\"\"Perform inference on a dataset\n",
        "  \n",
        "  Args:\n",
        "    input_queue: input queue with the images to be preprocessed.\n",
        "    output_queue: queue with the output images.\n",
        "    compression_rate(float): float number between 0-100 which represents the compression rate\n",
        "          in percentage terms. For simulation it represents the sleep time in seconds\n",
        "    simulation(boolean): if simulation or real run\n",
        "    model(string): the deep learning model that will be used on the images\n",
        "    \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_queue, output_queue, compression_rate, simulation = True, model = None):\n",
        "      self.input_queue = input_queue\n",
        "      self.output_queue = output_queue\n",
        "      self.simulation = simulation\n",
        "      \n",
        "      if simulation:\n",
        "        self.sleep = compression_rate\n",
        "        \n",
        "      else:\n",
        "        self.compression_rate = compression_rate\n",
        "        self.model = model\n",
        "      \n",
        "  def __iter__(self):\n",
        "      return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    if self.simulation:\n",
        "      self.input_queue.get()\n",
        "      sleep(self.sleep)\n",
        "      self.output_queue.put('a')\n",
        "      return\n",
        "    #else:\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gB8zg1058ccW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test"
      ]
    },
    {
      "metadata": {
        "id": "NuXhLLbd8cCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = load(\"/content/drive/My Drive/Photos\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYNANVMX8gyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initializing queues\n",
        "\n",
        "queue_1 = JoinableQueue()\n",
        "queue_2 = JoinableQueue()\n",
        "queue_3 = JoinableQueue()\n",
        "\n",
        "#Loading\n",
        "\n",
        "process_1 = Process(target = image_loader, args = (data, queue_1), daemon=True)\n",
        "process_1.start()\n",
        "\n",
        "#Preprocessing\n",
        "\n",
        "process_2 = Process(target = preprocessing, args = (queue_1, queue_2, (300,300)), daemon=True)\n",
        "process_2.start()\n",
        "\n",
        "#Inference\n",
        "\n",
        "process_3 = Process(target = inference, args = (queue_2, queue_3, 2), daemon=True)\n",
        "process_3.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ekOi8kTP8xR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a59d2201-6a4b-4b6f-c809-bc8074c79ece"
      },
      "cell_type": "code",
      "source": [
        "#Inserting another image\n",
        "\n",
        "next(image_loader(data, queue_1))\n",
        "next(preprocessing(queue_1, queue_2, (300,300)))\n",
        "next(inference(queue_2, queue_3, 2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LncueE_e8zi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "94f6cba9-7b70-43ef-e4b0-b96b5a22a07a"
      },
      "cell_type": "code",
      "source": [
        "#Number of items in each queue\n",
        "\n",
        "print(\"queue 1 size: \", queue_1.qsize())\n",
        "print(\"queue 2 size: \", queue_2.qsize())\n",
        "print(\"queue 3 size: \", queue_3.qsize())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queue 1 size:  0\n",
            "queue 2 size:  0\n",
            "queue 3 size:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eZC1Zjh881cY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}