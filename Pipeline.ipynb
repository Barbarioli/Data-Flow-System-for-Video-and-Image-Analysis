{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Barbarioli/Pipeline/blob/master/Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "TasSVUUR73wj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Pipeline"
      ]
    },
    {
      "metadata": {
        "id": "IA8Pp2gN78Bw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Packages"
      ]
    },
    {
      "metadata": {
        "id": "4KiBe_rk7yUG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from multiprocessing import Process, JoinableQueue, Pool, Manager, cpu_count\n",
        "from time import sleep\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Ljwpzf18IYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7236d642-3cb7-4b16-a022-cdb9e427c20f"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41vxb3oj8KOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Photos\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k6xg58fu8Udp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Loading"
      ]
    },
    {
      "metadata": {
        "id": "8xRzf1SV8Vkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load(path):\n",
        "  \"\"\"\n",
        "  path: path to the photos to be loaded\n",
        "  \"\"\"\n",
        "  image_files = sorted([os.path.join(path, file) for file in os.listdir(path) if file.endswith('.jpg')])\n",
        "  return image_files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rvq2xaSA8WyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Operators"
      ]
    },
    {
      "metadata": {
        "id": "tb_TKmFe8Ypc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class image_loader(object):\n",
        "  \"\"\"Load images from a list of paths to a queue in order to be processed.\n",
        "  \n",
        "  Args:\n",
        "    data: list of paths to all images.\n",
        "    queue: queue to where the loaded images will be added.\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, data, queue):\n",
        "    self.queue = queue\n",
        "    self.data = iter(data)\n",
        "    \n",
        "  def __iter__(self):  \n",
        "    return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    if len(data) > 0:\n",
        "      self.queue.put(imread(data[-1]))\n",
        "      data.pop()\n",
        "      return\n",
        "    \n",
        "    else:\n",
        "      raise StopIteration\n",
        "      \n",
        "      \n",
        "class preprocessing(object):\n",
        "  \"\"\"Preprocess images resizing, cropping and converting to tensor\n",
        "  \n",
        "  Args:\n",
        "    input_queue: input queue with the images to be preprocessed.\n",
        "    output_queue: queue with the output images.\n",
        "    output_size (tuple): desired image size in a tuple of (height, width).\n",
        "    crop (boolean): randomly crop the image. If cropped it will not be resized.\n",
        "    totensor (boolean): if the images should be converted to tensor.\n",
        "    \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_queue, output_queue, output_size, crop = False, totensor = False):\n",
        "    self.input_queue = input_queue\n",
        "    self.output_queue = output_queue\n",
        "    self.size = output_size\n",
        "    self.crop = crop\n",
        "    self.tensor = totensor\n",
        "    \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "      \n",
        "  def __next__(self):\n",
        "    if self.input_queue.qsize() != 0:\n",
        "      \n",
        "      image = self.input_queue.get()\n",
        "      \n",
        "      if self.crop:\n",
        "        h, w = image.shape[:2]\n",
        "        new_h, new_w = self.size\n",
        "        top = np.random.randint(0, h - new_h)\n",
        "        left = np.random.randint(0, w - new_w)\n",
        "        image = image[top: top + new_h,\n",
        "                     left: left + new_w]\n",
        "        \n",
        "      else:\n",
        "        image = resize(image, self.size, anti_aliasing = True)\n",
        "      \n",
        "      if self.tensor:\n",
        "        image = image.transpose((2,0,1))\n",
        "        image = torch.from_numpy(image)\n",
        "        \n",
        "      self.output_queue.put(image)\n",
        "      \n",
        "      \n",
        "      \n",
        "class inference(object):\n",
        "  \"\"\"Perform inference on a dataset\n",
        "  \n",
        "  Args:\n",
        "    input_queue: input queue with the images to be preprocessed.\n",
        "    output_queue: queue with the output images.\n",
        "    compression_rate(float): float number between 0-100 which represents the compression rate\n",
        "          in percentage terms. For simulation it represents the sleep time in seconds\n",
        "    simulation(boolean): if simulation or real run\n",
        "    model(string): the deep learning model that will be used on the images\n",
        "    \n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, input_queue, output_queue, compression_rate, simulation = True, model = None):\n",
        "      self.input_queue = input_queue\n",
        "      self.output_queue = output_queue\n",
        "      self.simulation = simulation\n",
        "      \n",
        "      if simulation:\n",
        "        self.sleep = compression_rate\n",
        "        \n",
        "      else:\n",
        "        self.compression_rate = compression_rate\n",
        "        self.model = model\n",
        "      \n",
        "  def __iter__(self):\n",
        "      return self\n",
        "  \n",
        "  def __next__(self):\n",
        "    if self.simulation:\n",
        "      self.input_queue.get()\n",
        "      sleep(self.sleep)\n",
        "      self.output_queue.put('a')\n",
        "      return\n",
        "    #else:\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gB8zg1058ccW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Test"
      ]
    },
    {
      "metadata": {
        "id": "NuXhLLbd8cCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = load(\"/content/drive/My Drive/Photos\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYNANVMX8gyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initializing queues\n",
        "\n",
        "queue_1 = JoinableQueue()\n",
        "queue_2 = JoinableQueue()\n",
        "queue_3 = JoinableQueue()\n",
        "\n",
        "#Loading\n",
        "\n",
        "process_1 = Process(target = image_loader, args = (data, queue_1), daemon=True)\n",
        "process_1.start()\n",
        "\n",
        "#Preprocessing\n",
        "\n",
        "process_2 = Process(target = preprocessing, args = (queue_1, queue_2, (300,300)), daemon=True)\n",
        "process_2.start()\n",
        "\n",
        "#Inference\n",
        "\n",
        "process_3 = Process(target = inference, args = (queue_2, queue_3, 2), daemon=True)\n",
        "process_3.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ekOi8kTP8xR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a59d2201-6a4b-4b6f-c809-bc8074c79ece"
      },
      "cell_type": "code",
      "source": [
        "#Inserting another image\n",
        "\n",
        "next(image_loader(data, queue_1))\n",
        "next(preprocessing(queue_1, queue_2, (300,300)))\n",
        "next(inference(queue_2, queue_3, 2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
            "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LncueE_e8zi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "94f6cba9-7b70-43ef-e4b0-b96b5a22a07a"
      },
      "cell_type": "code",
      "source": [
        "#Number of items in each queue\n",
        "\n",
        "print(\"queue 1 size: \", queue_1.qsize())\n",
        "print(\"queue 2 size: \", queue_2.qsize())\n",
        "print(\"queue 3 size: \", queue_3.qsize())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "queue 1 size:  0\n",
            "queue 2 size:  0\n",
            "queue 3 size:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eZC1Zjh881cY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}